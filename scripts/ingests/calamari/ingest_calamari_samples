import sys
import logging
sys.path.append(".")
from astropy.io import ascii
from simple import REFERENCE_TABLES
from astrodb_utils import load_astrodb

from astrodb_utils.sources import (
    find_source_in_db,
    ingest_source,
    logger,
    AstroDBError,
)

from astrodb_utils.publications import (
    find_publication,
    ingest_publication
)

from simple.utils.companions import (
    ingest_companion_relationships,
)

astrodb_utils_logger = logging.getLogger("astrodb_utils")
logger.setLevel(logging.DEBUG)  # Set logger to INFO/DEBUG/WARNING/ERROR/CRITICAL level
astrodb_utils_logger.setLevel(logging.DEBUG)

SAVE_DB = False  # save the data files in addition to modifying the .db file
RECREATE_DB = True  # recreates the .db file from the data files
SCHEMA_PATH = "simple/schema.yaml"
db = load_astrodb(
    "SIMPLE.sqlite",
    recreatedb=RECREATE_DB,
    reference_tables=REFERENCE_TABLES,
    felis_schema=SCHEMA_PATH,
)

link = (
    "scripts/ingests/calamari/calamari_data.csv"
)
link_2 = (
    "scripts/ingests/calamari/calamari_refs.csv"
)
calamari_table = ascii.read(
    link,
    format="csv",
    data_start=1,
    header_start=0,
    guess=False,
    fast_reader=False, 
    delimiter=",",
)

ref_table = ascii.read(
    link_2,
    format="csv",
    data_start=0,
    header_start=0,
    guess=False,
    fast_reader=False, 
    delimiter=",",
)

sources_ingested = 0
sources_already_exists = 0
ref_ingested = 0
companions_ingested = 0
ref_already_exists = 2 #Roth24 and Schl03 already exist in database

def getRef(ref_index):
    ref = ref_index.split(',')[0]
    ref_link = ref_table[int(ref)]['ADS']
    if 'iopscience' not in ref_link or 'harvard.edu' not in ref_link:
        ref_link = ref_table[int(ref)]['Link']
    return ref_link

def extractADS(link):
    start = link.find('abs/')+4
    end = link.find('/abstract')
    ads = link[start:end]
    ads = ads.replace("%26", "&")
    return ads

def extractDOI(link):
    link = str(link)
    if 'iopscience' in link:
        start = link.find('article/')+8
        doi = link[start:]
        doi = doi.replace("/pdf", "")
    else:
        start = link.find('doi.org/')+8
        doi=link[start:]
    return doi

def otherReferencesList(ref):
    #get all the ids/indexes of the references
    ids = ref.split(", ")
    result = []
    for id in ids:
        link = ref_table[int(id)]['ADS']
        if 'iopscience' not in link or 'harvard.edu' not in link:
            link = ref_table[int(id)]['Link']
        if 'harvard.edu' in link:
            bibcode = extractADS(link)
            pub_result=find_publication(
                db=db,
                bibcode=bibcode
            )
            if pub_result[0]:
                result.append(pub_result[1])
            else:
                print(f"Warning: Publication not found for bibcode {bibcode}")
        elif 'iopscience' in link or 'doi.org' in link:
            doi=extractDOI(link)
            pub_result=find_publication(
                db=db,
                doi=doi
            )
            if pub_result[0]:
                result.append(pub_result[1])
            else:
                print(f"Warning: Publication not found for doi {doi}")
        else:
            reference= ref_table[int(id)]['Ref']
            reference= reference.replace("+", "")
            reference=reference[0:4] + reference[-2:]
            pub_result=find_publication(
                db=db,
                reference=reference
            )
            if pub_result[0]:
                result.append(pub_result[1])
            else:
                print(f"Warning: Publication not found for reference {reference}")
    print("final result"+str(result))
    return result

#ingest publication: Curr20
ingest_publication(
    db=db,
    doi = "10.3847/2041-8213/abc631"
)
ref_ingested+=1

for row in ref_table:
    #ingest publications
    #get the ADS link
    pub = row['ADS']
    #if the link doesn't provide the ADS key directly...
    pub_2 = row['Link']
    #if link provides ADS
    if 'harvard.edu' in pub:
        bib = extractADS(pub)
        print(bib)
        pub_found = find_publication(
            db = db,
            bibcode = bib
        )
        if pub_found[0] == False:
            ingest_publication(
                db=db,
                bibcode= bib
            )
            ref_ingested+=1
        else:
            ref_already_exists+=1
    #if link provides doi
    if 'iopscience' in pub:
        doi = extractDOI(pub)
        pub_found = find_publication(
            db=db,
            doi=doi,
        )
        if pub_found[0] == False:
            ingest_publication(
                db=db,
                doi= doi
            )
            ref_ingested+=1
        else:
            ref_already_exists+=1
    if 'doi.org' in pub_2:
        doi = extractDOI(pub_2)
        pub_found = find_publication(
            db=db,
            doi=doi,
        )
        if pub_found[0] == False:
            ingest_publication(
                db=db,
                doi= doi
            )
            ref_ingested+=1
        else:
            ref_already_exists+=1
    if pub == None:
        continue


#ingest source WISE J124332.17+600126.6
ingest_source(
    db=db,
    source = "WISE J124332.17+600126.6",
    reference="Fahe21",
    ra=190.88386,
    dec=60.023957,
    ra_col_name="ra",
    dec_col_name="dec"
)
sources_ingested+=1

# #ingest source BD+60 1417
# ingest_source(
#     db=db,
#     source = "BD+60 1417",
#     reference="Fahe21",
#     ra = 190.88386,
#     dec = 60.023957,
#     ra_col_name="ra",
#     dec_col_name="dec"
# )
# sources_ingested+=1

row_index=0
#ingest the sources
for row in calamari_table:
    #read in row
    Dec = row['Dec']
    RA = row['RA']
    object = str(row['Object'])
    primary = str(row['Primary'])

    # check the object in the row is in the DB
    #if not, ingest
    obj_result = find_source_in_db(db=db, source = object, ra=RA, dec=Dec, ra_col_name="ra", dec_col_name="dec")
    ref_list = otherReferencesList(calamari_table[row_index]['Ref'])
    if len(obj_result)==0:
        if(len(ref_list)>1):
            ingest_source(
                db=db,
                source = object,
                reference = ref_list[0],
                other_reference= ",".join(map(str, ref_list[1:])),
                ra = RA,
                dec = Dec,
                ra_col_name="ra",
                dec_col_name="dec"
            )
            sources_ingested+=1
        else:
            ingest_source(
                db=db,
                source = object,
                reference=ref_list[0],
                ra = RA,
                dec = Dec,
                ra_col_name = "ra",
                dec_col_name = "dec"
            )
            sources_ingested+=1
    else:
        sources_already_exists+=1

    # check the primary in the row is in the DB
    #if not, ingest
    primary_result = find_source_in_db(db=db, source = primary, ra=RA, dec=Dec, ra_col_name="ra", dec_col_name="dec")
    if len(primary_result)==0:
        if(len(ref_list)>1):
            ingest_source(
                db=db,
                source = primary,
                reference = ref_list[0],
                other_reference= ",".join(map(str, ref_list[1:])),
                ra = RA,
                dec = Dec,
                ra_col_name="ra",
                dec_col_name="dec"
            )
            sources_ingested+=1
        else:
            ingest_source(
                db=db,
                source = primary,
                reference=ref_list[0],
                ra = RA,
                dec = Dec,
                ra_col_name = "ra",
                dec_col_name = "dec"
            )
            sources_ingested+=1
    else:
        sources_already_exists+=1
    row_index+=1
# i=0
# for row in calamari_table:
#     #ingest companion relationships
#     object = str(row['Object'])
#     primary = str(row['Primary'])
#     #UCD, or object, as the child
#     ingest_companion_relationships(
#         db=db,
#         source = object,
#         companion_name = primary,
#         relationship = "Child",
#         reference = ref_list[i]
#     )
#     #Primary as the parent
#     ingest_companion_relationships(
#         db=db,
#         source = primary,
#         companion_name = object,
#         relationship = "Parent",
#         reference = ref_list[i]
#     )
#     i+=1

logger.info(f"references ingested:{ref_ingested}")  # 10 references ingested
logger.info(f"references already exists:{ref_already_exists}")  # 24 references due to preexisting data
logger.info(f"total:{ref_ingested+ref_already_exists}")  # 34 references total
logger.info(f"sources ingested:{sources_ingested}")  # 12 ingested
logger.info(f"sources already exists:{sources_already_exists}")  # 105 due to preexisting data
logger.info(f"total:{sources_ingested+sources_already_exists}")  # 116 sources total
logger.info(f"primary ingested:{primary_ingested}")  #  ingested
print(skipped_sources)
# WRITE THE JSON FILES
if SAVE_DB:
    db.save_database(directory="data/")