import sys
import logging
sys.path.append(".")
from astropy.io import ascii
from simple import REFERENCE_TABLES
from astrodb_utils import load_astrodb

from astrodb_utils.sources import (
    find_source_in_db,
    ingest_source,
    logger,
    AstroDBError,
)

from astrodb_utils.publications import (
    find_publication,
    ingest_publication
)

from simple.utils.companions import (
    ingest_companion_relationships,
)

astrodb_utils_logger = logging.getLogger("astrodb_utils")
logger.setLevel(logging.DEBUG)  # Set logger to INFO/DEBUG/WARNING/ERROR/CRITICAL level
astrodb_utils_logger.setLevel(logging.DEBUG)

SAVE_DB = False  # save the data files in addition to modifying the .db file
RECREATE_DB = True  # recreates the .db file from the data files
SCHEMA_PATH = "simple/schema.yaml"
db = load_astrodb(
    "SIMPLE.sqlite",
    recreatedb=RECREATE_DB,
    reference_tables=REFERENCE_TABLES,
    felis_schema=SCHEMA_PATH,
)

link = (
    "scripts/ingests/calamari/calamari_data.csv"
)
link_2 = (
    "scripts/ingests/calamari/calamari_refs.csv"
)
calamari_table = ascii.read(
    link,
    format="csv",
    data_start=1,
    header_start=0,
    guess=False,
    fast_reader=False, 
    delimiter=",",
)

ref_table = ascii.read(
    link_2,
    format="csv",
    data_start=0,
    header_start=0,
    guess=False,
    fast_reader=False, 
    delimiter=",",
)

sources_ingested = 0
ref_ingested = 0
companions_ingested = 0
ref_already_exists = 2 #Roth24 and Schl03 already exist in database

def getRef(ref_index):
    ref = ref_index.split(',')[0]
    ref_link = ref_table[int(ref)]['ADS']
    return ref_link

def extractADS(link):
    start = link.find('abs/')+4
    end = link.find('/abstract')
    ads = link[start:end]
    ads = ads.replace("%26", "&")
    return ads


def extractDOI(link):
    if 'iopscience' in link:
        start = link.find('article/')+8
        doi = link[start:]
        doi = doi.replace("/pdf", "")
    else:
        start = link.find('doi.org/')+8
        doi=link[start:]
    return doi

#ingest publication: Curr20
ingest_publication(
    db=db,
    doi = "10.3847/2041-8213/abc631"
)
ref_ingested+=1

#ingest publication: Fahe22
# ingest_publication(
#     db=db,
#     doi="10.3847/1538-4357/ac2499",
# )
# ref_ingested+=1

for row in ref_table:
    #ingest publications
    #get the ADS link
    pub = row['ADS']
    #if the link doesn't provide the ADS key directly...
    pub_2 = row['Link']
    #if link provides ADS
    if 'harvard.edu' in pub:
        bib = extractADS(pub)
        print(bib)
        pub_found = find_publication(
            db = db,
            bibcode = bib
        )
        if pub_found[0] == False:
            ingest_publication(
                db=db,
                bibcode= bib
            )
            ref_ingested+=1
            print("publications ingested "+str(ref_ingested))
        else:
            ref_already_exists+=1
            print("publications already exist " +str(ref_already_exists))
    #if link provides doi
    if 'iopscience' in pub:
        doi = extractDOI(pub)
        pub_found = find_publication(
            db=db,
            doi=doi,
        )
        if pub_found[0] == False:
            ingest_publication(
                db=db,
                doi= doi
            )
            ref_ingested+=1
            print("publications ingested " +str(ref_ingested))
        else:
            ref_already_exists+=1
            print("publications already exist " +str(ref_already_exists))
    if 'doi.org' in pub_2:
        doi = extractDOI(pub_2)
        pub_found = find_publication(
            db=db,
            doi=doi,
        )
        if pub_found[0] == False:
            ingest_publication(
                db=db,
                doi= doi
            )
            ref_ingested+=1
            print("publications ingested " +str(ref_ingested))
        else:
            ref_already_exists+=1
            print("publications already exist " +str(ref_already_exists))
    if pub == None:
        continue
#a=0
"""
for row in calamari_table:
    #ingest the sources
    #read in row
    Dec = row['Dec']
    RA = row['RA']
    object = str(row['Object'])
    primary = str(row['Primary'])

    # check the object in the row is in the DB
    #if not, ingest
    obj_result = find_source_in_db(db=db, source = object, ra=RA, dec=Dec, ra_col_name="ra", dec_col_name="dec")
    if len(obj_result)==0:
        ingest_source(
            db=db,
            source = object,
            reference = ref_list[a],
            ra = RA,
            dec = Dec,
            ra_col_name="ra",
            dec_col_name="dec"
        )

    # check the primary in the row is in the DB
    #if not, ingest
    primary_result = find_source_in_db(db=db, source = primary, ra=RA, dec=Dec, ra_col_name="ra", dec_col_name="dec")
    if len(primary_result)==0:
        print(primary, primary_result)
        ingest_source(
            db=db,
            source = primary,
            reference = ref_list[a],
            ra = RA,
            dec = Dec,
            ra_col_name="ra",
            dec_col_name="dec"
        )
    a+=1
i=0
for row in calamari_table:
    #ingest companion relationships
    object = str(row['Object'])
    primary = str(row['Primary'])
    #UCD, or object, as the child
    ingest_companion_relationships(
        db=db,
        source = object,
        companion_name = primary,
        relationship = "Child",
        reference = ref_list[i]
    )
    #Primary as the parent
    ingest_companion_relationships(
        db=db,
        source = primary,
        companion_name = object,
        relationship = "Parent",
        reference = ref_list[i]
    )
    i+=1
    """

logger.info(f"references ingested:{ref_ingested}")  #  ingested
logger.info(f"references already exists:{ref_already_exists}")  # due to preexisting data
logger.info(f"total:{ref_ingested+ref_already_exists}")  #  total
# WRITE THE JSON FILES
if SAVE_DB:
    db.save_database(directory="data/")